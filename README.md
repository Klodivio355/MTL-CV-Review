# MTL-CV-Review
A paper gathering repository based on our [review paper](https://arxiv.org/abs/2307.14382) entitled 'When Multi-Task Learning Meets Partial Supervision: A Computer Vision Review' accepted by Proceedings of the IEEE (2024).

## Table of Contents
- [Partially-Supervised Multi-Task Learning](#PS-MTL)

## Partially-Supervised Multi-Task Learning
### 1. Self-supervised Representation Learning
* Multi-task Self-Supervised Visual Learning (ICCV, 2017) [[paper](https://arxiv.org/abs/1708.07860)]
* Multi-Task Self-Training for Learning General Representations (ICCV, 2021) [[paper](https://arxiv.org/abs/2108.11353)]
* Multi-Task Self-Supervised Visual Representation Learning for Monocular Road Segmentation (IEEE, 2018) [[paper](https://ieeexplore.ieee.org/document/8486472)]
* Multi-task Self-supervised Object Detection via Recycling of Bounding Box Annotations (CVPR, 2019) [[paper](https://openaccess.thecvf.com/content_CVPR_2019/papers/Lee_Multi-Task_Self-Supervised_Object_Detection_via_Recycling_of_Bounding_Box_Annotations_CVPR_2019_paper.pdf)] [[code](https://github.com/wonheeML/mtl-ssl)]
* Self-Supervised Multi-Task Pretraining Improves Image Aesthetic Assessment (CVPR, 2021) [[paper](https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/papers/Pfister_Self-Supervised_Multi-Task_Pretraining_Improves_Image_Aesthetic_Assessment_CVPRW_2021_paper.pdf)]
* Anomaly Detection in Video via Self-Supervised and Multi-Task Learning (CVPR, 2021) [[paper](https://arxiv.org/abs/2011.07491)] [[code](https://github.com/lilygeorgescu/AED-SSMTL)]
* 12-in-1: Multi-Task Vision and Language Representation Learning (CVPR, 2020) [[paper](https://arxiv.org/abs/1912.02315)]
* Sound and Visual Representation Learning with Multiple Pretraining Tasks (CVPR, 2022) [[paper](https://arxiv.org/abs/2201.01046)]
* MultiMAE: Multi-modal Multi-task Masked Autoencoders (ECCV, 2022) [[paper](https://arxiv.org/abs/2204.01678) [[code](https://github.com/EPFL-VILAB/MultiMAE)]

### 2. Semi-Supervised Learning
* Semi-Supervised Multitask Learning (NIPS, 2007) [[paper](https://proceedings.neurips.cc/paper_files/paper/2007/file/a34bacf839b923770b2c360eefa26748-Paper.pdf)]
* Semi-supervised Multi-task Learning with Task Regularizations (ICDM, 2009) [[paper](https://ieeexplore.ieee.org/document/5360282)]
* Three Ways to Improve Semantic Segmentation with Self-Supervised Depth Estimation (CVPR, 2021) [[paper](https://arxiv.org/abs/2012.10782)] [[code](https://github.com/lhoyer/improving_segmentation_with_selfsupervised_depth)]
* Partly Supervised Multitask Learning (ICMLA, 2020) [[paper](https://arxiv.org/abs/2005.02523)]
* Semi-supervised Multi-task Learning for Semantics and Depth (WACV, 2022) [[paper](https://arxiv.org/abs/2110.07197)]
* A Novel Multi-Task Self-Supervised Representation Learning Paradigm (AIID, 2021) [[paper](https://ieeexplore.ieee.org/document/9456562)]
* Robust Learning Through Cross-Task Consistency (CVPR, 2020) [[paper](https://arxiv.org/abs/2006.04096)] [[code](https://github.com/EPFL-VILAB/XTConsistency)]
* Learning Multiple Dense Prediction Tasks from Partially Annotated Data (CVPR, 2022) [[paper](https://arxiv.org/abs/2111.14893)] [[code](https://github.com/VICO-UoE/MTPSL)]

### 3. Few-Shot Learning
* The Natural Language Decathlon: Multitask Learning as Question Answering (ICLR, 2019) [[paper](https://arxiv.org/abs/1806.08730)] [[code](https://github.com/salesforce/decaNLP)]
* Improving Few-Shot Learning with Auxiliary Self-Supervised Pretext Tasks (ArXiv, 2021) [[paper](https://arxiv.org/abs/2101.09825)] [[code](https://github.com/nathanielsimard/improving-fs-ssl)]
* MTFormer: Multi-Task Learning via Transformer and Cross-Task Reasoning (ECCV, 2022) [[paper](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136870299.pdf)] [[code](https://github.com/xiaogang00/MTFormer)]
* Universal Few-shot Learning of Dense Prediction Tasks with Visual Token Matching (ICLR, 2023) [[paper](https://arxiv.org/abs/2303.14969)] [[code](https://github.com/GitGyun/visual_token_matching)]




